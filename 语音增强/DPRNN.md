# [DUAL-PATH RNN for audio separation](https://blog.csdn.net/qq_43473149/article/details/111353033?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522163671934716780264061811%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=163671934716780264061811&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-4-111353033.pc_search_result_control_group&utm_term=DPRNN&spm=1018.2226.3001.4187)
基于[深度](https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6&spm=1001.2101.3001.7020)学习的语音分离的最新研究证明了时域方法优于传统的基于时频的方法。与时频域方法不同，时域分离系统通常会接收包含大量时间步长的输入序列，这给建模超长序列带来了挑战。传统的递归神经网络（RNN）由于优化困难而无法有效地建模如此长的序列，而一维卷积神经网络（1-D CNN）的接收场小于序列长度时则无法执行话语级序列建模。在本文中，我们提出了双路径递归神经网络（DPRNN），这是一种在深层结构中组织RNN层以对极长序列进行建模的简单有效的方法。 DPRNN将长序列输入分成较小的块，并迭代应用块内和块间操作，其中输入长度可以与每个操作中原始序列长度的平方根成比例。实验表明，通过用DPRNN代替一维CNN并在时域音频分离网络（TasNet）中应用样本级别的建模，可以在WSJ0-2mix上获得最新的性能，而体积要比以前的最佳系统小20倍。

### 1. INTRODUCTION

基于深度学习的语音分离的最新进展激发了研究界对时域方法的兴趣[1-6]。 与标准时[频域](https://so.csdn.net/so/search?q=%E9%A2%91%E5%9F%9F&spm=1001.2101.3001.7020)方法相比，**时域方法旨在共同对幅度和相位信息进行建模**，并允许针对时域和频域可区分标准进行直接优化[7-9]。

当前的时域分离系统主要可分为自适应前端和直接回归方法。 自适应前端方法旨在用可微变换代替短时傅立叶变换（STFT），以构建可以与分离网络一起学习的前端。 像传统的时频域方法一样，将分离过程应用于前端输出，将分离过程应用于频谱图输入[3-5]。 与传统的时频分析范式无关，这些系统能够在窗口大小和前端基本功能的数量方面灵活得多。 另一方面，直接回归方法通常通过使用某种形式的一维[卷积神经网络](https://so.csdn.net/so/search?q=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&spm=1001.2101.3001.7020)（1-D CNN）来学习从输入混合信号到基本干净信号的回归函数，而没有明确的前端[2， 7、10]。

这两个类别之间的共同点是**它们都依赖于对超长输入序列的有效建模**。 直接回归方法在波形样本级别执行分离，而样本数量通常可以是数万个，有时甚至更多。 自适应前端方法的性能还取决于窗口大小的选择，其中较小的窗口以明显更长的前端表示为代价提高了分离性能[4，11]。 由于传统的顺序建模网络（包括RNN和1-D [CNN](https://so.csdn.net/so/search?q=CNN&spm=1001.2101.3001.7020)）很难学习这种长期的时间依赖性，因此这带来了另外的挑战[12]。 此外，与具有动态感受野的RNN不同，具有固定感受野且长度小于序列长度的一维CNN不能充分利用序列级依赖性[13]。


# DPCRN

将crn中的lstm换成dprnn  其中块相当于stft的帧，块内就是一帧的频谱，块间就是帧与帧之间，块内用BLSTM 块间用lstm 这样是因果的