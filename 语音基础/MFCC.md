# [语音信号的梅尔频率倒谱系数(MFCC)的原理讲解及python实现](https://www.cnblogs.com/LXP-Never/p/10918590.html)

**Filter Banks**和**MFCCs**的步骤。值得注意的是，计算**滤波器组**所需的所有步骤都是由语音信号的性质和人类对这些信号的感知所驱动的。相反，计算**MFCC**所需的额外步骤是由一些机器学习算法的限制所驱动的。需要离散余弦变换（DCT）来对滤波器组系数**去相关化**，该过程也称为**白化**。特别是，当高斯混合模型 - 隐马尔可夫模型（GMMs-HMMs）非常受欢迎时，MFCC非常受欢迎，MFCC和GMM-HMM共同演化为自动语音识别（ASR）的标准方式[2](https://tspace.library.utoronto.ca/bitstream/1807/44123/1/Mohamed_Abdel-rahman_201406_PhD_thesis.pdf)。**随着深度学习在语音系统中的出现，人们可能会质疑MFCC是否仍然是正确的选择，因为深度神经网络不太容易受到高度相关输入的影响，因此离散余弦变换（DCT）不再是必要的步骤。值得注意的是，离散余弦变换（DCT）是一种线性变换，因此在语音信号中丢弃一些高度非线性的信息是不可取的**。

Filter Banks和MFCC对比：

-   **计算量**：MFCC是在FBank的基础上进行的，所以MFCC的计算量更大
-   **特征区分度**：FBank特征相关性较高（相邻滤波器组有重叠），MFCC具有更好的判别度，这也是在大多数语音识别论文中用的是MFCC，而不是FBank的原因
-   **信息量**：FBank特征的提取更多的是希望符合声音信号的本质，拟合人耳接收的特性。MFCC做了DCT去相关处理，因此Filter Banks包含比MFCC更多的信息
-   使用对角协方差矩阵的GMM由于忽略了不同特征维度的相关性，MFCC更适合用来做特征。
-   DNN/CNN可以更好的利用Filter Banks特征的相关性，降低损失。

从目前的趋势来看，因为神经网络的逐步发展，FBank特征越来越流行。

　　质疑傅里叶变换是否是必要的操作是明智的。鉴于傅立叶变换本身也是线性运算，忽略它并尝试直接从时域中的信号中学习可能是有益的。实际上，最近的一些工作已经尝试过，并且报告了积极的结果。然而，傅立叶变换操作是很难学习的操作，可能会增加实现相同性能所需的数据量和模型复杂性。此外，在进行短时傅里叶变换（stft）时，我们假设信号在这一短时间内是平稳的，因此傅里叶变换的线性不会构成一个关键问题。