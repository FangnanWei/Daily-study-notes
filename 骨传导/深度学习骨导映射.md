
最开始，BILSTM 单说话人，需要归一化，除以max，然后求对数幅度谱的均值和方差，再归一化，求骨导和气导的，然后训练
最后需要用气导的均值和方差。

但是是单说话人的，多说话人效果不行。

试着用增强的思路，求mapping



WAVEUNET


DCCRN 求实部和虚部的MSE 但只能学习到4000HZ 4000HZ往上不行，试着改损失函数
加幅度谱的MSE 发现效果不行，高频不是有效信息，只是杂音。
选用多分辨率的STFTloss，结果比上一个好，但也是高频是杂音，且低频效果被影响

试着尝试搬运频谱的方式，类似带宽扩展，结果不行，和带宽扩展的论文所述不理想。集中处理搬移的频谱了，低频没管，高频也没什么表现

DPCRN loss为三个的MSE  但细节不太一样


如果数据不够  eben和seanet中有模拟数据的方法。频响曲线和互相关 TemporalTransforms 类中的一个方法，用于对音频信号进行低通滤波。它使用了一个双二阶滤波器，通过 filt-filt 技巧实现了零相移滤波。具体来说，它首先对音频信号进行了反转，然后使用 lowpass_biquad 函数进行滤波，最后再次反转得到最终结果。其中，滤波器的截止频率和品质因数可以通过参数 cutoff_freq 和 q_factor 进行设置。如果 determinist 参数为 False，则会在每次调用该方法时随机生成一个在 [0.8, 1.2] 范围内的系数，用于对截止频率和品质因数进行随机扰动。最后，该方法还对滤波后的信号进行了去噪处理，去除了滤波器引入的前向和反向延迟。

SEANET  谷歌的增强网络

尝试使用带宽扩展  
GAN网络 loss 时  detach 
EBEN 改进SEANET  里面audiounet结果结果和我之前crn类似，高频上不去，解释了值钱的原因  seanet也是做骨导气导融合增强的。
seanet生成器借鉴melgan 空洞卷积与跳跃连接 

残差层的空洞卷积，增加感受野，类似meigan hifigan 

[(41 封私信 / 7 条消息) MelGan - 搜索结果 - 知乎 (zhihu.com)](https://www.zhihu.com/search?type=content&q=MelGan)   讲解判别器结果，多尺度 连续下采样后输出feature 和 score  讲解eben以及melgan中用的铰链损失hinge loss（但github上的代码用的最小二乘损失）
替换featurematching_loss为multi-resolution stft loss会缩短收敛时间 

生成器loss  advloss 叫对抗loss，是score由判别器生成   featuremaploss，feature也是由判别器生成   辅助loss 就是正常的那种loss，比如multistft

[细读经典：HiFiGAN，拥有多尺度和多周期判别器的高效声码器 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/406341310)   讲解网络，记忆weight norm eval时去掉它 
这篇文章讲的特别好 里面讲了网络为何设计，
里面讲到上采样容易出现棋盘效应  
为了避免棋盘效应因此每次转置卷积上采样之后，都会跟着一个多感受野融合multi-receptive field fusion (MRF)（MRF）的残差网络，以进一步提升样本点的生成质量  dilation=1,3,5 这就是seanet中的残差结构

自适应权重  函数的作用是计算动态调整重构损失和对抗损失的权重。具体来说，它计算了重构损失和对抗损失在某一层的梯度，并将它们的范数作为权重的分母和分子，然后将它们相除得到权重
![image](https://cdn.staticaly.com/gh/andyye1999/picx-images-hosting@master/20230516/image.34g60oc5c540.webp)

![[Pasted image 20230516175059.png]]

里面讲解了**最小二乘损失**

[HiFiGAN (francis-komizu.github.io)](https://francis-komizu.github.io/notes/speech-synthesis/vocoder/hifigan/HiFiGAN.html)  里面讲判别器

多尺度和melgan一样，周期判别器是将音频隔着抽取，然后reshape成2d 进行2d的卷积

GAN网络训练困难，生成器loss上升，改成多次生成器，一次鉴别器试试 问了作者，GAN网络收敛不能根据loss判断，可根据客观指标。上升是正常的

BWE  HiFi-GAN+ 里面有作者GAN的训练技巧


或者不用GAN，直接用time或者freq的loss 效果不太好


骨气融合 SEANET   大象声科中的通入基频，fbank 方位角等特征学习幅度谱
