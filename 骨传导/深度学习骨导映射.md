
最开始，BILSTM 单说话人，需要归一化，除以max，然后求对数幅度谱的均值和方差，再归一化，求骨导和气导的，然后训练
最后需要用气导的均值和方差。

但是是单说话人的，多说话人效果不行。

试着用增强的思路，求mapping



WAVEUNET


DCCRN 求实部和虚部的MSE 但只能学习到4000HZ 4000HZ往上不行，试着改损失函数
加幅度谱的MSE 发现效果不行，高频不是有效信息，只是杂音。
选用多分辨率的STFTloss，结果比上一个好，但也是高频是杂音，且低频效果被影响

试着尝试搬运频谱的方式，类似带宽扩展，结果不行，和带宽扩展的论文所述不理想。集中处理搬移的频谱了，低频没管，高频也没什么表现

DPCRN loss为三个的MSE  但细节不太一样


SEANET  谷歌的增强网络

尝试使用带宽扩展  
GAN网络 loss 时  detach 
EBEN 改进SEANET  里面audiounet结果结果和我之前crn类似，高频上不去，解释了值钱的原因

残差层的空洞卷积，增加感受野，类似meigan hifigan 

[melgan]([(41 封私信 / 7 条消息) MelGan - 搜索结果 - 知乎 (zhihu.com)](https://www.zhihu.com/search?type=content&q=MelGan))   讲解判别器结果，多尺度 连续下采样后输出feature 和 score  讲解eben以及melgan中用的铰链损失hinge loss（但github上的代码用的最小二乘损失）

生成器loss  advloss 叫对抗loss，是score由判别器生成   featuremaploss，feature也是由判别器生成   辅助loss 就是正常的那种loss，比如multistft

[hifigan]([细读经典：HiFiGAN，拥有多尺度和多周期判别器的高效声码器 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/406341310))    讲解网络，记忆weight norm eval时去掉它 

里面讲解了**最小二乘损失**


GAN网络训练困难，生成器loss上升，改成多次生成器，一次鉴别器试试 问了作者，GAN网络收敛不能根据loss判断，可根据客观指标。上升是正常的

BWE  HiFi-GAN+ 里面有作者GAN的训练技巧


或者不用GAN，直接用time或者freq的loss

