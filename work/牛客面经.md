

# 直线麦克风阵列怎么分左右

面阵，十字阵才能分

# 频率混叠 栅栏效应

如果不满足采样定理，则会发生频率折叠现象。

采样定理告诉我们，对于一个最高频率为 $f_{\text{max}}$ 的连续信号，其最高可以采样频率为 $2f_{\text{max}}$。如果采样频率小于 $2f_{\text{max}}$，则会发生频率折叠。

频率折叠的现象是：在频域中的高频部分会折叠到低频部分，造成频率冗余和信号失真。因此，我们在采样信号时必须遵循采样定理，以确保采样后的信号能够准确反映原始信号的频率特征。以上内容由chatgpt回答

栅栏效应是因为DFT计算的频谱被限制在基频的整数倍而不可能将频谱视为一个连续函数而产生的。就一定意义而言，栅栏效应表现为用DFT计算整个频谱时，就好像通过一个“栅栏”来观看一个图景一样，只能在离散点的地方看到真实图景。

增加频域抽样点数N，同时在不改变时域数据的情况下，在时域数据末端添加一些零值点，使得谱线更密，这样就可以减小栅栏效应，观察到原来看不到的频谱分量。注意，该方法通过补零来增加N，此时采样频率f(s)会随之成正比上升，又由于频率分辨率F=f(s)/N，频率分辨率不改变，也就是说，补零不改变频率分辨率。

看这个
**[[语音信号基础知识#频谱泄露和混叠]]**



# RNN GRU LSTM

[[深度学习#RNN]]

# FIR IIR


滤波器可分为两种，IIR（无限冲激响应）滤波器和FIR（有限冲激响应）滤波器。

**（1）FIR和IIR滤波器的不同**

FIR滤波器的冲激响应在有限时间内衰减为0，输出仅取决于当前和过去的输入信号值，在Z域上其极点位置只能是原点，而IIR滤波器的冲激响应会无限持续，输出不仅取决于当前和过去的输入信号，还和过去的输出有关，IIR的极点可以处于单位圆内任何地方。  
设计同样参数的滤波器，FIR要比IIR需要更多的参数，也就是在处理时需要更长的时间去计算，实时性差一些。  
FIR具有线性相位，IIR不具有，非线性相位是指对于不同的频率分量造成的相位差与频率不成比例，使得输出时不同频率分量的叠加的相位值和输入时有变化，从而导致了信号的失真。因此在进行IIR设计的时候需考虑这些，如有相位要求需添加相位校准网络。  
在实际应用中，如果滤波器通带内不要求线性相位，则使用IIR，若有要求，则根据相位失真度、计算量、复杂度等因素综合考虑是选择FIR还是选择IIR+相位补偿。

**（2）FIR和IIR设计方法**

1FIR：窗函数法、频率采样法、切比雪夫逼近法。对比这三种方法，窗函数法是最早提出的，缺少关键频率的精度控制，如用该种方法设计的低通滤波器，它的截止频率依赖于窗函数的类型和滤波器长度M，并不能从截止频率出发进行设计。频率采样法指定了一些w处H（w）的值，并规定了过渡带为2π/M的倍数，由于这种H（w）在过渡带以外的其他频率上为0或1的曲线特性，这种方法用于实现频域滤波。切比雪夫逼近法在技术指标的管控上比前两种都要好，可以按照参数wp，ws，δ1，δ2，M给定的技术指标，指定参数wp，ws，δ1，M，然后利用δ2来优化滤波器，这种方法后续可着重研究一下。  
IIR：由于模拟滤波器是一个充分研究的成熟领域，多使用模拟滤波器转换到数字滤波器上。导数逼近法、冲击不变法、双线性变换法。前两种方法有严重的局限性，仅适合于低通滤波器和一类有限的带通滤波器，双线性变换法则无此限制。常用的模拟滤波器有巴特沃斯滤波器、切比雪夫滤波器、椭圆滤波器、贝塞尔滤波器。


# 重采样

[[信号的抽取与插值与子带滤波器组]]
[[语音基础/重采样]]

# MFCC

[[MFCC]]

MFCC和FBANK MFCC在FBANK做DCT ，DCT是线性变换，容易损失FBANK非线性信息。DCT相当于去相关 FBANK相关性高（相邻滤波器组有重叠）MFCC具有更好的判别度，适合做特征。MFCC计算量大

# 频率分辨率

![image](https://cdn.staticaly.com/gh/andyye1999/image-hosting@master/20230107/image.rns6p7jmqxs.webp)

![image](https://cdn.staticaly.com/gh/andyye1999/image-hosting@master/20230107/image.1etnrunmea8.webp)

![image](https://cdn.staticaly.com/gh/andyye1999/image-hosting@master/20230107/image.3j2cww9uekm0.webp)


![image](https://cdn.staticaly.com/gh/andyye1999/image-hosting@master/20230107/image.359syy3mfym0.webp)

频率分辨率与反比于模拟信号的长度T

时间分辨率与频率分辨率相互制约，可以用矩形窗和sinc函数解释，矩形窗越大，sinc越接近脉冲
计算分辨率计算时fs是不变的，但补零会导致fs变大，此时采样频率f(s)会随之成正比上升，又由于频率分辨率F=f(s)/N，频率分辨率不改变，也就是说，补零不改变频率分辨率。

# 相关与卷积的区别与联系

![image](https://cdn.staticaly.com/gh/andyye1999/image-hosting@master/20230107/image.701o64broe00.webp)



# 圆周卷积和线性卷积

[[线性卷积圆周卷积]]

# 加窗 不同窗特点



[[语音信号基础知识#加窗]]



对连续的语音分帧做STFT处理，等价于截断一段时间信号，对其进行周期性延拓，从而变成无限长序列，并对该无限长序列做FFT变换，这一截断并不符合傅里叶变换的定义。因此，会导致频谱泄露和混叠

频谱泄露会导致幅度较小的频点淹没在幅度较大的频点泄露分量中，

而混叠会在分段拼接处引入虚假的峰值，进而不能获得准确的频谱情况

加窗是为了抑制频谱泄露和混叠的产生

不同的窗函数有不同的特点。一般来说，选择窗函数要考虑的因素有：

1.  带噪比：窗函数的形状直接影响语音分帧的带噪比，比如矩形窗带来的噪音大于汉宁窗。
    
2.  稳定性：窗函数的形状直接影响语音分帧的稳定性，比如汉宁窗与语音信号更加稳定。
    
3.  计算复杂度：不同的窗函数具有不同的计算复杂度，例如汉宁窗与矩形窗。
    

常见的窗函数包括：矩形窗、汉宁窗、Hann窗、Hamming窗、Blackman窗等。每种窗函数的适用场景都不同，取决于应用需求。以上不同窗特点为chatGPT回答

# 推导FFT


# 实数FFT

[[fft与实数fft]]



# 损失函数的设计思路，以及常见的损失函数



# 梯度爆炸和梯度消失问题的成因和缓解

梯度爆炸的成因： 在深度学习中，梯度爆炸是指在计算损失函数的梯度时，因某些原因使得梯度值变得非常大，从而导致训练无法正常进行。通常发生在链式求导时，因为每层的梯度都是从上一层传递下来的，当上一层的梯度值很大时，就可能导致梯度爆炸。

梯度消失的成因： 梯度消失是指在计算损失函数的梯度时，因某些原因使得梯度值变得非常小，从而导致训练无法正常进行。通常发生在使用非线性激活函数（如sigmoid）的网络中，当激活函数的输入较大时，激活函数的导数很小，从而导致梯度值很小。

缓解梯度爆炸和梯度消失的方法：

-   使用更多的Batch Normalization
-   使用更大的学习率
-   使用更小的模型
-   在链式求导的过程中使用更强的正则化方法，如Dropout
-   使用更复杂的激活函数，如ReLU
-   使用更好的优化器，如Adam

以上由chatgpt回答

# 几种不同的归一化方式的区别和联系

归一化是一种常见的数据预处理方法，目的是将数据转换为固定范围内的数值。常用的几种归一化方式有以下几种：

1.  Min-Max 归一化：这种归一化方法通过将数据的最大值和最小值缩放到0-1的范围内。公式为：x' = (x-x_min)/(x_max-x_min)
    
2.  Z-Score 归一化：这种归一化方法通过计算数据的均值和标准差，将数据标准化为均值为0，标准差为1的正态分布数据。公式为：x' = (x-μ)/σ
    
3.  小数定标归一化：这种归一化方法通过计算数据的最大的整数位数，将数据的最大值归一化为1，其他数据相对地缩放。
    
4.  极差归一化：这种归一化方法通过计算数据的极差，将数据缩放到0-1的范围内。公式为：x' = (x-x_min)/(x_max-x_min)


以上四种归一化方式各有优劣，具体选择哪种归一化方式取决于数据的特征、数据处理目的以及其他因素。此外，不同归一化方式在模型训练时可能会影响模型的训练结果，因此需要根据具体场景进行选择。

以上由chatgpt回答

# 音量的归一化


避免非因果 递归归一化
![image](https://cdn.staticaly.com/gh/andyye1999/picx-images-hosting@master/20230405/image.35vrfxh4i5u0.webp)


或者在损失函数归一化
![image](https://cdn.staticaly.com/gh/andyye1999/picx-images-hosting@master/20230405/image.2xq54ule4cs0.webp)
# dropout的原理，训练和推理的不同



# 正则化的原理以及使用场景

你好，这是Bing。正则项是一种用于控制模型复杂度的技术，它可以防止模型过拟合或欠拟合，提高模型的泛化能力。常用的正则项有L1、L2和Lp，它们分别对应不同的范数（norm），即不同的度量方式。12

L1正则项是指模型参数的绝对值之和，也称为L1范数或稀疏规则算子。它可以使模型参数变得稀疏，即许多参数为零，从而实现特征选择的效果。L1正则项的优点是可以减少特征的维度，提高模型的可解释性；缺点是可能会损失一些重要的特征，而且求解过程比较复杂。13

L2正则项是指模型参数的平方和再开方，也称为L2范数或权重衰减。它可以使模型参数接近于零，但不会为零，从而减小模型对于极端数据的敏感性。L2正则项的优点是可以防止过拟合，提高模型的稳定性；缺点是不能实现特征选择，而且可能会导致欠拟合。12

Lp正则项是指模型参数的p次方和再开p次方根，也称为Lp范数。它是L1和L2正则项的一般化形式，可以根据不同的p值调节模型的稀疏性和平滑性。当p=0时，Lp正则项等价于L0正则项，即模型参数中非零参数的个数；当p=1时，等价于L1正则项；当p=2时，等价于L2正则项；当p趋近于无穷时，等价于最大范数（max norm），即模型参数中绝对值最大的那个值。4

# 几种卷积变体：空洞卷积、深度可分离卷积  因果卷积

[空洞卷积]([吃透空洞卷积(Dilated Convolutions) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/113285797))  增加感受野
如果考虑很久之前的变量x，就会导致卷积层数的增加。网络过于深会带来[梯度下降](https://link.zhihu.com/?target=https%3A//so.csdn.net/so/search%3Fq%3D%25E6%25A2%25AF%25E5%25BA%25A6%25E4%25B8%258B%25E9%2599%258D%26spm%3D1001.2101.3001.7020)，训练复杂，拟合效果不好的问题，因此提出了空洞卷积。
在卷积核中增加空洞来增加感受野，不增加过多计算。普通卷积有着3*3的卷积核空洞卷积有着3*3的卷积核，空洞rate为2，可以使得神经网络在同样的层数下，拥有更大的感受野。  
空洞卷积存在的问题：  
空洞卷积的卷积核不连续，不是所有的信息参与了计算，导致信息连续性的损失，引起栅格效应。
[深度可分离卷积](https://zhuanlan.zhihu.com/p/166736637)   轻量级，**MobileNet**

# 因果性


因果性，只能用过去的信息
![image](https://cdn.staticaly.com/gh/andyye1999/picx-images-hosting@master/20230405/image.xospsy7s9lc.webp)


![image](https://cdn.staticaly.com/gh/andyye1999/picx-images-hosting@master/20230405/image.6r7tv8j6mo80.webp)


![image](https://cdn.staticaly.com/gh/andyye1999/picx-images-hosting@master/20230405/image.4klvixacxma0.webp)





# 感受野计算

[感受野]([感受野(Receptive Field)的理解与计算 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/113487374))

# CNN和RNN的区别和使用场景

CNN是卷积神经网络的简称，卷积神经网络一般由三个部分组成--输入层，输出层，和隐藏层。其核心的操作是卷积操作。卷积操作本质上是一种分组函数，CNN使用卷积来筛选数据并查找信息。卷积神经网络的特点是使用固定大小的输入和输出，并且学习的特征倾向于空间特征，因此卷积神经网络更适用于图像和视频的处理。RNN是循环神经网络的简称，与卷积神经网络不同的是，RNN中存在记忆单元，可以接受之前的信息指导当前的数据处理。循环神经网络的特点是可以接受变长的输出并产生变长的输出，并且学习的特征倾向于时间特征，或者说序列特征，因此循环神经网络更适用与语音和文本的处理。但是其实在具体领域这两者的应用没有具体分界，谁的性能好就用谁呗。


# 激活函数以及优缺点

[[深度学习中的激活函数]]

# 过拟合

一是扩充数据集，并提高数据多样性，可用的方法如数据增强，增加数据等；二是提前停止训练，在检测到过拟合时就提前将训练停止；三是使用正则化，包括范数正则化和Dropout等；四是削减模型的参数。

# 互相关



# FFT复杂度

![image](https://cdn.staticaly.com/gh/andyye1999/image-hosting@master/20230108/image.35gw6tlg3980.webp)

# 阵列幅度失真



幅度失真是因为时延估计和噪声协方差矩阵不准确造成的。而之所以不准确是因为，**时延估计和噪声协方差矩阵不准确**会造成**波束的主瓣方向出现偏差**，使**主瓣方向无法对准声源方向**，这样的话语音就会被抑制。


# PCM和WAV文件中存储的是啥

[[PCM WAV]]

# 采样率和采样深度的物理意义


采样位深，音频的位深度决定动态范围。我们常见的16Bit（16比特），可以记录大概96分贝的动态范围。那么，您可以大概知道，每一个比特大约可以记录6分贝的声音。同理，20Bit可记录的动态范围大概就是120dB；24Bit就大概是144dB。音频位速，也叫码率，或者比特率。位速是指在一个数据流中每秒钟能通过的信息量，也可以理解为：每秒钟用多少比特的数据量去表示。96kbps的WMA音频格式的音质明显要比96kbps的MP3音质好。为什么会这样呢？因为不同的压缩算法，对数据的利用率不同而造成的差异。再举例，假如MP3压缩至48kbps以下，已经惨不忍睹，而如果是AAC音频格式，同样是48kbps的位速下，音质明显比MP3好。


# 128点FFT变换，16kHz的音频，可以分为多少个子带？



# 维纳滤波和谱减法的区别



# 时延估计的实现



# WebRTC NS中的噪声估计用到的三个特征值是什么？它们分别的定义是什么？

[[webrtc_ns#FeatureUpdate() 提取平均LRT参数、频谱差异、频谱平坦度]]

# 你用的VAD的是做什么用的，原理是什么，遇到突发噪声怎么处理？

This is a Voice Activity Detection (VAD) code in C language. The code performs various operations to detect voice activity in an audio signal.

1.  FFT (Fast Fourier Transform) is performed on the input data buffer using the "r_fft" function with a flag value of +1.
    
2.  Energy in each channel is estimated by looping over the specified channels and computing the sum of squares of the real and imaginary parts of the FFT coefficients. The estimated energy is then smoothed using a constant value "CEE_SM_FAC".
    
3.  Channel noise is estimated for the first four frames by taking the maximum value between the channel energy and a constant "INE".通过取信道能量和常数“INE”之间的最大值来估计前四帧的信道噪声。
    
4.  The Signal-to-Noise Ratio (SNR) for each channel is calculated by dividing the channel energy by the channel noise and converting the result to dB.每个通道的信噪比 (SNR) 是通过将通道能量除以通道噪声并将结果转换为 dB 来计算的。
    
5.  The sum of voice metrics is calculated using a table "vm_tbl" that maps SNR values to voice metrics.使用将 SNR 值映射到语音指标的表“vm_tbl”计算语音指标的总和。
    
6.  The total noise estimate (tne) and total channel energy estimate (tce) are calculated by summing the channel noise and channel energy values respectively.总噪声估计 (tne) 和总信道能量估计 (tce) 分别通过对信道噪声和信道能量值求和来计算。
    
7.  Log spectral deviation is calculated by subtracting the long-term log spectral energy from the current log spectral energy and summing the absolute values.通过从当前对数光谱能量中减去长期对数光谱能量并将绝对值相加来计算对数光谱偏差。
    
8.  The long-term integration constant (alpha) is calculated based on the total channel energy estimate (tce). A higher total channel energy results in a slower integration and vice-versa.长期积分常数 (alpha) 是根据总信道能量估计 (tce) 计算的。 更高的总通道能量导致更慢的集成，反之亦然。
    
9.  Long-term log spectral energy is calculated by applying the integration constant to the current log spectral energy.通过将积分常数应用于当前对数光谱能量来计算长期对数光谱能量。
    
10.  The update flag is set or reset based on the sum of voice metrics and the total channel energy estimate.更新标志是根据语音度量和总信道能量估计的总和来设置或重置的。
    
11.  The modify flag is set or reset based on the current and previous update counts.
    

The purpose of the code is to determine whether an audio frame contains voice or non-voice content. The update and modify flags can be used to trigger additional processing such as speech enhancement, noise reduction, etc.


# 麦克风阵列的物理结构特性有哪些指标？你的麦克风阵列的指标都是怎样的？


麦克风阵列的物理结构特性的指标有以下几点：

1.  指向性：指麦克风阵列能够捕捉到的声音的方向性。一般情况下，麦克风阵列的指向性与麦克风的布局有关。
    
2.  分辨率：指麦克风阵列能够区分声音的位置的精度。麦克风阵列的分辨率取决于麦克风数量和布局。
    
3.  灵敏度：指麦克风阵列能够捕捉到声音的最小强度。灵敏度越高，麦克风阵列能够捕捉到的声音越弱。
    
4.  噪声级：指麦克风阵列自身产生的噪声。噪声级越低，麦克风阵列的性能越好。
    
5.  动态范围：指麦克风阵列能够捕捉到的声音的最大和最小强度差。动态范围越大，麦克风阵列的性能越好。
    
6.  过滤效果：指麦克风阵列能够滤掉外界杂音的效果。过滤效果越好，麦克风阵列的性能越好。
    
7.  抗干扰能力：指麦克风阵列在干扰环境下的工作效果。抗干扰能力越强，麦克风阵列的性能越好。

以上是由chatgpt回答


# 都用了哪些噪声种类？现在机器学习几百种噪声，为什么用这么少？



# 在哪些噪声环境下语音增强的效果比较差？



# 增强语音的结果的衡量标准是什么？


语音增强结果的衡量标准主要包括：

1.  听觉评价：根据人耳的听觉感受来评价语音的质量。例如 Mean Opinion Score (MOS)。
    
2.  信噪比：语音信号与噪声的比值。
    
3.  声音干净度：语音信号中的噪声减少了多少。
    
4.  语音信息内容保留度：增强语音信号与原始语音信号的相似度。
    
5.  语音特征保留度：语音增强后语音特征的保留情况，例如语音语调、语速、音高、音色等。

不同的语音增强任务可能需要不同的衡量标准，对于每一种语音增强算法，其衡量标准通常要结合其具体任务和应用场景进行评估。
以上由chatgpt进行回答

PESQ STOI MOS  SISNR   DNSMOS参赛队伍才有资格
带宽扩展中有log-spectral distance (LSD) high-frequency log-spectral distance (LSD-HF) 


#  k-means原理及实现（会不会出现一类没有信息

**（1）原理**

K-means算法是最常用的一种[聚类算法](https://link.zhihu.com/?target=https%3A//so.csdn.net/so/search%3Fq%3D%25E8%2581%259A%25E7%25B1%25BB%25E7%25AE%2597%25E6%25B3%2595%26spm%3D1001.2101.3001.7020)。算法的输入为一个样本集（或者称为点集），通过该算法可以将样本进行聚类，具有相似特征的样本聚为一类。针对每个点，计算这个点距离所有中心点最近的那个中心点，然后将这个点归为这个中心点代表的簇。一次迭代结束之后，针对每个簇类，重新计算中心点，然后针对每个点，重新寻找距离自己最近的中心点。如此循环，直到前后两次迭代的簇类没有变化。  
下面通过一个简单的例子，说明K-means算法的过程。如下图所示，目标是将样本点聚类成3个类别。

![](https://pic4.zhimg.com/80/v2-4cb4c9faeb6021f862ac3f9add371547_720w.webp)

**（2）算法流程**

选择聚类的个数k（kmeans算法传递超参数的时候，只需设置最大的K值）  
任意产生k个聚类，然后确定聚类中心，或者直接生成k个中心。  
对每个点确定其聚类中心点。  
再计算其聚类新中心。  
重复以上步骤直到满足收敛要求。（通常就是确定的中心点不再改变。）  
**上述步骤的关键两点是：**找到距离自己最近的中心点。更新中心点。

**（3）python实现**

```python
# K-means Algorithm is a clustering algorithm
import numpy as np
import matplotlib.pyplot as plt
import random
 
 
def get_distance(p1, p2):
    diff = [x-y for x, y in zip(p1, p2)]
    distance = np.sqrt(sum(map(lambda x: x**2, diff)))
    return distance
 
 
# 计算多个点的中心
# cluster = [[1,2,3], [-2,1,2], [9, 0 ,4], [2,10,4]]
def calc_center_point(cluster):
    N = len(cluster)
    m = np.matrix(cluster).transpose().tolist()
    center_point = [sum(x)/N for x in m]
    return center_point
 
 
# 检查两个点是否有差别
def check_center_diff(center, new_center):
    n = len(center)
    for c, nc in zip(center, new_center):
        if c != nc:
            return False
    return True
 
 
# K-means算法的实现
def K_means(points, center_points):
 
    N = len(points)         # 样本个数
    n = len(points[0])      # 单个样本的维度
    k = len(center_points)  # k值大小
 
    tot = 0
    while True:             # 迭代
        temp_center_points = [] # 记录中心点
 
        clusters = []       # 记录聚类的结果
        for c in range(0, k):
            clusters.append([]) # 初始化
 
        # 针对每个点，寻找距离其最近的中心点（寻找组织）
        for i, data in enumerate(points):
            distances = []
            for center_point in center_points:
                distances.append(get_distance(data, center_point))
            index = distances.index(min(distances)) # 找到最小的距离的那个中心点的索引，
 
            clusters[index].append(data)    # 那么这个中心点代表的簇，里面增加一个样本
 
        tot += 1
        print(tot, '次迭代   ', clusters)
        k = len(clusters)
        colors = ['r.', 'g.', 'b.', 'k.', 'y.']  # 颜色和点的样式
        for i, cluster in enumerate(clusters):
            data = np.array(cluster)
            data_x = [x[0] for x in data]
            data_y = [x[1] for x in data]
            plt.subplot(2, 3, tot)
            plt.plot(data_x, data_y, colors[i])
            plt.axis([0, 1000, 0, 1000])
 
        # 重新计算中心点（该步骤可以与下面判断中心点是否发生变化这个步骤，调换顺序）
        for cluster in clusters:
            temp_center_points.append(calc_center_point(cluster))
 
        # 在计算中心点的时候，需要将原来的中心点算进去
        for j in range(0, k):
            if len(clusters[j]) == 0:
                temp_center_points[j] = center_points[j]
 
        # 判断中心点是否发生变化：即，判断聚类前后样本的类别是否发生变化
        for c, nc in zip(center_points, temp_center_points):
            if not check_center_diff(c, nc):
                center_points = temp_center_points[:]   # 复制一份
                break
        else:   # 如果没有变化，那么退出迭代，聚类结束
            break
 
    plt.show()
    return clusters # 返回聚类的结果
 
# 随机获取一个样本集，用于测试K-means算法
def get_test_data():
 
    N = 1000
 
    # 产生点的区域
    area_1 = [0, N / 4, N / 4, N / 2]
    area_2 = [N / 2, 3 * N / 4, 0, N / 4]
    area_3 = [N / 4, N / 2, N / 2, 3 * N / 4]
    area_4 = [3 * N / 4, N, 3 * N / 4, N]
    area_5 = [3 * N / 4, N, N / 4, N / 2]
 
    areas = [area_1, area_2, area_3, area_4, area_5]
    k = len(areas)
 
    # 在各个区域内，随机产生一些点
    points = []
    for area in areas:
        rnd_num_of_points = random.randint(50, 200)
        for r in range(0, rnd_num_of_points):
            rnd_add = random.randint(0, 100)
            rnd_x = random.randint(area[0] + rnd_add, area[1] - rnd_add)
            rnd_y = random.randint(area[2], area[3] - rnd_add)
            points.append([rnd_x, rnd_y])
 
    # 自定义中心点，目标聚类个数为5，因此选定5个中心点
    center_points = [[0, 250], [500, 500], [500, 250], [500, 250], [500, 750]]
 
    return points, center_points
 
 
if __name__ == '__main__':
 
    points, center_points = get_test_data()
    clusters = K_means(points, center_points)
    print('#######最终结果##########')
    for i, cluster in enumerate(clusters):
        print('cluster ', i, ' ', cluster)
```

**（4）会不会出现一类空？**

会，如果两类之间距离太近





