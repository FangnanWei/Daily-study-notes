# 自适应滤波
[[FDAF自适应滤波器算法综述]]
[[FXLMS]]
# webrtc
[[webrtc_ns]]
[[webrtc-aec]]

# 降噪

[[语音增强理论与实践]]

# 深度学习

[[基于深度学习的语音增强概述]]

# 波束形成

[[MVDR]]
[[GSC]]

# 骨导项目

## VAD

[[语音活动检测模块]]

## 频域RLS

[[频域RLS]]

Background noise reduction 和 Statistical noise reduction 区别是前者是在VAD判决为噪声时

## 谱线增强

对每帧每个频段计算能量，算自相关和互相关
然后根据VAD结果为语音和相关性（互相关/自相关）大，采用快步长进行参考麦的能量平滑
找到前12个较大的能量，将剩余的比第12个小的所有频点能量相加取平均
将它除以每个频点能量开根号，与主麦信号相乘

代码在BCE工程中  md中删除了，防止保密协议

为什么直方图用log，因为为了使容器的容量小，语音波动大，转换成db后波动小

## 硬件

### 简化webrtc aec

fft换成自己的，我们的fft跟原来的相比，需要除以64.不知道为什么 因为我们的FFT本身就是是真正的FFT/64的 128点FFT是除以64  256点FFT是除以128
不能轻易使用malloc，dsp容易溢出，将它们事先放进结构体中，这样直接占用栈空间
nlp中步长的判决简单化

NLMS滤波器采用10阶系数 也是10个block  原来webrtc是12阶


分块的BLOCK_LEN为64
每次读取160点，缓存为64+160+160+384点采样值
远端信号进行FFT后缓存20个128点FFT值

### 定点化

[[定点化#神经网络权重的定点化]]

统计降噪的定点化FFT中+16384的目的是  在进行右移的同时，因为运算结果是向下取整的，为了避免因为右移造成的精度损失，所以在每个数的末尾加上一个偏移量，即16384L，以便获得一个更精确的结果。相当于+0.5 为了四舍五入 得到更高精度 尤其是像自适应滤波器或者FFT这种循环迭代的定点化  这么做的目的是为了使运算结果四舍五入为最接近的整数，以保证运算结果的精度。

webrtc的NSX中fft定点化inst->stages = inst->order 80点->128FFt 为7 160点->256FFT 为8
FFT的定点化之后的Q值为(norm-stages)

窗函数或者查表的数组浮点为1时，定点为32767，不是32768

log函数怎么实现看那个定点化文档的PDF，最后有详细解释
log10(x) = log10(2) *  log2(x)

用电脑去模拟指令集，芯片是恒玄2500，arm指令集。32位分为高16位低16位
basic_op.c 这个文件中有以下几种函数：

add、sub、abs_s、shl、shr等，用于对16位整数进行加减、绝对值、左移、右移等运算。123
L_add、L_sub、L_abs、L_shl、L_shr等，用于对32位整数进行加减、绝对值、左移、右移等运算。123
mult、round等，用于对16位整数进行乘法和四舍五入运算，并返回16位整数。123
L_mult等，用于对16位整数进行乘法运算，并返回32位整数。123
mac_r、msu_r等，用于对两个16位整数进行乘累加或乘累减运算，并返回16位整数。123
L_mac、L_msu等，用于对两个16位整数进行乘累加或乘累减运算，并返回32位整数

mpy32_16 相当于32位乘16位数再右移15位
mpy32_32 相当于32位乘32位数再右移31位
div_s 除法 将分母取norm 上面的1再右移norm位 得到结果是Q15的数 函数的分子必须小于分母

DIV_32类似，32位的除法
除法转换为乘法，但Qzhi还是按除法算，即除法后的Q 是 之前的Q减去分母norm之前的Q值

长时平滑agc定点化函数
平方根[[平方根]]

### 后置滤波

基音滤波 仿照rnnoise 和编解码器中的后置滤波，因为音色增强中求了基音周期了，看rnnoise中的后置滤波模块[[RNNoise#[RNNoise超详细解读](https://zhuanlan.zhihu.com/p/397288851)]]

# 阵列

[[阵列软著总结]]

[[环形麦克风阵列]]
